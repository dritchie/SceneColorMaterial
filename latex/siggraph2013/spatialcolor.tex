We formulate the problem of generating colorings for a pattern template as finding high-probability colorings. Formally, we define a pattern template $\pattern = (\segments, \groups, \colorVars, \features)$, where $\groups$ is a set of individual groups $\group$, and $\segments$ is a set of individual segments $\segment$, $\colorVars$ is a set of color variables, and $\features$ is a set of features over different groups, segments, and adjacencies within the pattern. Each $\group$ and $\segment$ is associated with a color variable $\colorVars(\group)$ and $\colorVars(\segment)$ respectively. All segments within a color group have the same color by definition, so $\colorVars(\text{group}(\segment)) = \colorVars(\segment)$. A coloring $\colors$ is an assignment of colors to color variables.

We model the probability of a coloring for a particular pattern template as a product of different terms $\term$:   
\begin{equation*}
 p(\colors | \pattern : \weights) = \frac{1}{Z_\pattern(\weights)} \prod_{\term \in \model} \exp{\frac{ \weights_\term \cdot \termStats(\colors, \pattern)}{t}}
\end{equation*}
where each term $\term$ scores the goodness of a color assignment based on a term-dependent sufficient statistics function $\termStats(\colors,\pattern)$, and the temperature $t$ affects the peakiness of the distribution. $\weights_\term$ indicates the weight of term. On example of a term is the overall color compatibility of the color assignment, where its associated sufficient statistic is based on the predicted compatibility rating of the five colors with the most area. This formulation of the probability distribution allows us to compare the weights of different terms to see which contribute most to predicting a good coloring. It is also general enough, such that we can add additional terms based on user feedback and constraints in order to guide the search.

In our model, we include terms for color compatibility and spatial terms for groups, segments, and segment adjacencies. The statistics function for each term will be detailed in the next sections. We also describe how factors over the color variables can be generated from each term, so we can sample high-probability colorings from the resulting factor graph.

\subsection{Color Compatibility}
\label{sec:colorCompat}

Previous work has shown that we can enhance the aesthetic appeal of an image by increasing the compatibility or harmony of image colors ~\cite{CohenOrHarmonization,DressUp,ColorizationUsingHarmony,ODonovan}. Thus, we include a color compatibility term to score the general appeal of the colors in an assignment, based on the compatibility model introduced by O'Donovan et al.~\shortcite{ODonovan}. The compatibility model was originally trained to predict the aesthetic ratings of 5-color themes, an ordered row of 5 colors. 

For the term's sufficient statistics function, we extract a color theme by taking the colors of the 5 largest color groups, and order them by size. If there are fewer than 5 color groups, we cycle the colors of the groups in order of size to fill the rest of theme. We then compute their log-normalized theme rating using O'Donovan's compatibility model. Informal inspection of 5-color patterns showed that size-ordering of the colors tended to produce themes that were rated higher than random orderings, though rated lower than the optimal ordering on average. Formally:
\begin{equation*}
\colorCompatTerm(\colors, \pattern) = \ln(\text{compat}(\text{theme}(\colors, \pattern))/5)
\end{equation*}
where $theme$ is the ordered theme extracted from a pattern and $compat$ is the predicted rating from the O'Donovan model.~\remark{D: Note that there is nothing special about the O'Donovan model; we could plug in any color compatibility/harmony model that allows us to `score' a set of colors}

\remark{S: To get more justification for the ordering criteria, we can also try looking at the ordered themes associated patterns and see if they look reasonable. I think we can also try getting the optimal rating of the top 5 colors in MATLAB (instead of having Scala pass permutations 120 times to MATLAB) to see how slow it is...or for comparison}.


\subsection{Spatial Compatibility}
\label{sec:spatialCompat}

As shown in Figure~\ref{fig:ColorCompatOnly}, general color compatibility alone does not predict good colorings, and can lead to TODO artifacts (i.e. adjacent regions with little perceptual separation and loud backgrounds). Good color assignments also depend on the properties of the regions and their spatial arrangement. 

To capture these dependencies, we include spatial terms over groups, segments, and adjacencies. Group and segment terms capture color dependencies on region features, and segment adjacency terms capture color dependencies on the relationship between nearby regions.

\textbf{Group and segment terms}
Both global group features as well as local segment features affect the appearance of a color assignment. The total area of a group and overall spread of its member segments correspond to the overall proportion and spread of its assigned color within an image. In addition, the size and shape of member segments may impact the color a group takes on. As an example, smaller segments may often be more saturated, and a group composed of many small segments may be more likely to be saturated than a group composed of a few small segments but also one large segment \remark{S: Made up example. Should probably find one that holds in our data}.   

In general, our spatial terms score color assignments based on the conditional probability of properties of colors (i.e. lightness or colorfulness) given either group, segment, or adjacency features. We compute probabilities over color properties instead of individual colors to allow for more generalization over different colors that have not been seen in the training examples.~\remark{D: This probably belongs before the `Group and segment terms' section, since it applies to all spatial terms.} For group and segment terms, we use the unary properties lightness and colorfulness in CIELAB space, a perception-based colorspace. We also use color name counts (counts of how many times a color is described with different names) and name saliency (how uniquely a color is named), as described by Heer and Stone~\shortcite{ColorNamingModels}.~\remark{D: I'm not sure how, but this list should stand out more---it shouldn't be buried in some text. A bulleted list is probably too much, though.	} While lightness and colorfulness capture perceptual properties of color, name saliency and color name counts capture more categorical properties. More details on the computation of these color properties and region features are included in the Appendix.~\remark{D: We haven't yet (even qualitatively) mentioned what the segment features are. We should do that somewhere in here.}

Our model includes one group and segment term per color property. The group term for property $\prop \in \unaryProps$ has the sufficient statistics function:
\begin{equation*}
 \groupTerm(\colors, \pattern) = \sum_{\group \in \groups} \ln p( \prop( \colors(\group) ) | \features(\group)) \cdot \size_\group
\end{equation*}
where $\size_\group$ is the size of the group $\group$ and $\features(\group)$ are the features of the $\group$. We weight the contribution of each group to the term statistics by its relative area as larger regions tend to have more impact on the appearance of a coloring. We'll refer to the group-specific inner-sum term $\ln p( \prop( \colors(\group) ) | \features(\group)) \cdot \size_\group$ as the group instance statistic $\groupInstStats(g)$. 

Similarly, the segment term for property $\prop$ has the statistics function:
 \begin{equation*}
 \segTerm(\colors, \pattern) = \sum_{\segment \in \segments} \ln p( \prop( \colors(\segment) ) | \features(\segment)) \cdot \size_\segment
 \end{equation*}
where $\size_\segment$ is the size of the segment $\segment$ and $\features(\segment)$ are the features of $\segment$. We'll refer to the segment-specific inner-sum term as the segment instance statistic $\segInstStats(s)$.

We generate factors over each color variable by gathering its associated group and segments and computing their instance statistics for each term. Formally:
 \begin{equation*}
 \factor_\pattern(\colorVars(\group)) = exp\left(\sum_{\prop \in \unaryProps} \groupInstStats(\group) \sum_{\segment \in \group} \segInstStats(\segment)\right) 
 \end{equation*}
\remark{D: Hmm. Yeah, this whole `relating things back to the more ``graphical'' notion of factor graphs' might not be a bad idea. It's a little confusing right now, though. I may take a crack at it.}

\textbf{Segment adjacency terms}
While group and segment terms model the dependency of color assignments on features of same-color regions, they do not capture relationships among different-color regions. In particular, adjacent color regions can have strong effects on their neighbor's perceived color, for example making colors seem more or less saturated or causing vibrating boundaries if adjacent lightness and colorfulness are too similar~\cite{AlbersInteractionOfColor}. Thus, we also add segment adjacency terms to the model.

Good color assignments to adjacent segments may depend on specific features of their adjacency. For example, a square enclosed by a thin border appears different than a square enclosed by a larger square, and different than a square side-by-side with another square. Thus, when computing features of an adjacency we include the features of the member segments as well as how much one neighbor encloses another. The Appendix contains more details on feature computation for adjacencies.~\remark{D: These anecdotal examples go by quickly and are hard to visualize. We could actually make some pictures...} 

Analogous to the group and segment terms, adjacency terms compute statistics based on the conditional probability distribution of binary color properties given the adjacency features. Binary color properties include relative lightness, relative colorfulness, perceptual distance in LAB space, and color name cosine similarity ~\cite{ColorNamingModels}.

The sufficient statistics function for each binary property is:
 \begin{equation*}
 \adjTerm(\colors, \pattern) =
 	\sum_{(\segment, \segprime) \in \adj(\pattern)}
 		\ln p( \prop( \colors(\segment), \colors(\segprime) ) | \features(\segment, \segprime) ) \cdot \adjStrength(\segment, \segprime) 
 \end{equation*}
 where $\adjStrength(\segment,\segprime)$ is the adjacency strength of $(\segment,\segprime)$. Again, we define the inner-sum term to be the adjacency instance statistic $\adjInstStats$.

 We generate factors over each adjacent pair of color variables:
  \begin{equation*}
 \factor_\pattern(\colorVars(\group), \colorVars(\groupprime)) = exp\left(\sum_{\prop \in \binaryProps}\sum_{(\segment, \segprime) \in \adj(\group, \groupprime)} \adjInstStats(\segment, \segprime)\right) 
 \end{equation*}


\subsection{Learning Probability Distributions}

As described previously, each group, segment, and adjacency term is associated with a conditional probability distribution (pdf) of the term's color property given instance features, from which it computes term statistics~\remark{D: What's an `instance feature?' (That's a devil's advocate question: \emph{I} know what it means, but a new reader might not)}. To learn these pdfs, we adapt the approach of Charpiat et al.~\shortcite{MultimodalColorization}, where we first discretize the distribution by binning property values. Bins are determined by K-means clustering on property values found in the training examples. However, we use multinomial logistic regression to predict the probability of a bin given a feature vector for an instance, instead of kernel density estimation on training instances that fall in the same bin. 

TODO: multinomial logistic regression instead of KDE+KNN because....advantage of not having to store training instances, faster at inference time (though a bit slower at training time), and performance seemed reasonable qualitatively (or, was no worse than KNN). In addition, inspecting coefficients could be informative.  

The specific form of the training input to the regression depends on the term. For example, for the group term statistics $\groupTerm$, training instances from the training dataset $\dataset$ have the form 

$(bin(\prop(\colors(\group))), \features(\group)) \in (\pattern, \colors) \in \dataset$ 

where the bin indicates the class label. To give each pattern template in the training set equal weight in the regression, we weight each group example by one over the number of groups in the template. Similar instances and instance weightings are used for segment and adjacency term regressions, but with the respective segment and adjacency features.~\remark{D: Mentioning the weighting is important for reproducibility, but showing the form of the examples feels confusing/distracting.}

Finally, to evaluate the probability density of a property value, we use kernel density estimation on the bins.~\remark{D: We should cite~\cite{ThemeEnhancement} here, as we based this part of the technique on theirs.} We set the number of bins to be ? and the bandwidth of the kernel to be ?.~\remark{D: Kernel bandwidth is set exactly the same as in~\cite{ThemeEnhancement}. Number of bins...still up in the air whether we will use cross-validation or `an empirically chosen value.'}

This approach is relatively fast. Because the features of a pattern template do not change during inference, we only need to compute the discretized conditional pdfs once per tuple of group, segment, or adjacency and their associated property when generating a coloring.~\remark{D: \emph{I} know what you mean, but I think readers would find this hard to parse. Maybe take a couple more sentences to make this clear?}

TODO: possibly mention importance of multimodality at the beginning..how approaches that predict some best property value (i.e. averaging), don't take that into account.~\remark{D: Agreed. This should probably go all the way up at the beginning of Section~\ref{sec:spatialCompat}, where we first introduce the use of CPDs.}

\remark{D: Do we want to end this section with a visualization of the factor graph for a simple, `toy' pattern template? Or would that confuse more than it would help?}