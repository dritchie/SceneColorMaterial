\section{Probabilistic Model}
\label{sec:model}

We have defined unary, pairwise, and global scoring functions for pattern color properties. Now, we combine them into one scoring function that evaluates the overall quality of a pattern coloring.

For this task, we turn to the language of \emph{probabilistic factor graphs}. A factor graph is a probabilistic graphical model that decomposes a complex probability distribution over multiple variables into a set of smaller \emph{factors} over subsets of the variables. In our case, the variables $\colorVars$ are the colors of each color group in a pattern, and the factors $\factor$ are derived from our scoring functions. Figure~\ref{fig:FactorGraph} shows an example of a factor graph for one simple pattern. The circles denote color variables, while squares denote different factors $\factor$. Edges in the graph connect each factor to the variables within its scope.

\begin{figure}[ht]
%\raisebox{4em}{\includegraphics[width=.2\columnwidth]{figs/factorGraphPattern}} &
%\includegraphics[width=.7\columnwidth]{figs/factorGraph} 
\centering
\includegraphics[width=0.85\columnwidth]{figs/factorGraphNew}
\caption{A factor graph for an example pattern template. Variable nodes are colored according to their corresponding color group in the pattern.}
\label{fig:FactorGraph}
\end{figure}

The factors connected to a single variable are derived from our unary scoring functions; they combine the score for a color group with the scores for all segments in that group:
%%
\begin{equation*}
 \factor^{\textrm{Unary}}_\prop(\colors_\group) =
 		\exp( \groupTermWeight \cdot \groupInstStats(\colors_\group)  \\
 		     + \segTermWeight \cdot \sum_{\segment \in \group} \segInstStats(\colors_\group)) 
\end{equation*}
%%
The $w$'s are weights that control the relative importance of each function; we will see how to set them later in this section.

The factors connecting two variables come from our pairwise scoring functions and combine the scores for all adjacencies which involve segments from two different color groups:
\begin{equation*}
\factor^{\textrm{Pairwise}}_\prop(\colors_\group, \colors_\groupprime) =
	\exp( \adjTermWeight \cdot \sum_{\mathclap{(\segment, \segprime) \in \adj(\group, \groupprime)}} \adjInstStats( \colors_\group, \colors_\groupprime))
\end{equation*}
%%
Finally, the factor connected to all five color variables enforces color compatibility:
%%
\begin{equation*}
\factor^{\textrm{Compat}}(\colors_1 \ldots \colors_5) = \exp(\colorCompatWeight \cdot \colorCompatInstStats(\colors_1 \ldots \colors_5))
\end{equation*}
%%
The probability distribution encoded by this factor graph is the normalized product of all of these factors:
%%
\begin{equation*}
p(\colors | \pattern : \weights) = \frac{1}{Z(\pattern : \weights)} \prod_{\factor} \factor(\textit{Scope}_\factor(\colors))
\end{equation*}
%%
Here, $\textit{Scope}_\factor$ selects the color variables connected to the factor $\factor$ and $Z(\pattern : \weights)$ is the pattern-dependent partition function that normalizes the distribution. The distribution is parameterized by the vector of factor weights $\weights$.


\subsection{Sampling}
\label{sec:sampling}

Generating good coloring suggestions reduces to sampling high-probability colorings from our model. We use the Metropolis-Hastings algorithm (MH), a variant of Markov Chain Monte Carlo (MCMC)~\cite{Metropolis,Hastings}. MH explores the coloring state space by \emph{proposing} candidate new states, which are accepted with probability proportional to their model score. We would also like our sampler to output a variety of suggestions, which requires that it explore many modes of the distribution. To do this efficiently, we use parallel tempering, a technique that runs multiple MCMC chains in parallel at different `temperatures' and swaps their states periodically~\cite{ParallelTempering}. `Hot' chains are more likely to take large jumps across the state space, whereas `cool' chains behave like local hill-climbing optimizers. The combined system of chains effectively explores and refines different coloring configurations.

Our sampler uses the following MH proposals:
\begin{itemize}
	\item{\textbf{Perturb} a randomly chosen color by $v \sim \mathcal{N}(0, \sigma)$ in RGB space}
	\item{\textbf{Swap} two randomly chosen colors}
\end{itemize}
where $\sigma$ varies linearly with the model temperature $t$, encouraging larger perturbations at high temperatures. The sampler chooses between these two proposals with a probability that also varies linearly with temperature. The sampler operates in RGB space since all RGB colors fall in the display gamut---which is not the case with \lab space---and the sampler should not waste time exploring colorings that cannot be visualized. Since the RGB color space is bounded, the perturbation proposal draws from a truncated normal distribution in order to maintain ergodicity of the MCMC chains~\cite{TruncatedGaussians}.

Finally, we use maximimum marginal relevance (MMR) to enforce diversity in the set of suggestions returned by the sampler~\cite{MMR}. MMR is a technique from information retrieval that re-ranks every item in a list according to a linear combination of relevance (model score, in our case) and similarity to the items preceding it. The similarity metric we use for two colorings $\colors$ and $\tilde{\colors}$ of a pattern is $- \sum_{\group \in \groups} {\size_\group \cdot ||\colors_\group - \tilde{\colors}_\group||}$, which is the area-weighted sum of \lab distances between the corresponding colors in each coloring.

\subsection{Weight Learning}
\label{sec:weights}

The factor graph model we have defined is parameterized by a vector of weights $\weights$. Setting these weights manually proves challenging, as it is not obvious which color properties matter most to the quality of a pattern coloring. Instead, we would like to set them automatically, using our training dataset as a guide.

We formulate the weight-tuning problem as one of \emph{maximum likelihood parameter estimation}: we would like to set the weights such that the training examples have high probability under the resulting model. We first rewrite the probability distribution encoded by our model from a weight-centric view
%%
\begin{equation*}
p(\colors | \pattern : \weights) = \frac{1}{Z(\pattern : \weights)} \prod_{w \in \weights} \exp(w \cdot \weightStats(\colors, \pattern))
\end{equation*}
%%
where $\weightStats(\colors, \pattern)$ sums all the scoring functions $\phi$ that share the weight $w$. We can then express the log-likelihood of the weights given a dataset $\dataset$ of pattern colorings:
%%
\begin{equation*}
\ell(\weights : \dataset) =
	\sum_{(\pattern, \colors) \in \dataset}
	(
		\sum_{w \in \weights}
			w \cdot \weightStats(\colors, \pattern)
	)			
		- \ln{Z(\pattern : \weights)}
\end{equation*}
%%
Convex log-likelihoods such as this are typically maximized via gradient ascent. The partial derivatives of this function with respect to the weights are
%% Partial derivatives
\begin{equation*}
\frac{\partial}{\partial w} \ell(\weights : \dataset) = 
	\sum_{(\pattern, \colors) \in \dataset}
			\weightStats(\colors, \pattern)
		- \expectation_\weights[\weightStats(\colorVars, \pattern)]
\end{equation*}
%%
where $\expectation_\weights$ denotes an expectation under the model with weights $\weights$. Unfortunately, these quantities are extremely expensive to compute: the expectation term requires probabilistic inference---an NP-complete problem---for every training pattern, for every iteration of gradient ascent.

This computational intractability has motivated the development of alternative, `biased' parameter estimation schemes which do not directly maximize the likelihood function but nevertheless yield parameters that give high likelihoods. We use one such method called \emph{Contrastive Divergence} (CD)~\cite{ContrastiveDivergence}. CD uses the following approximation to the likelihood gradient:
%% CD gradient
\begin{equation*}
CD^k_w(\weights : \dataset) = 
	\sum_{(\pattern, \colors) \in \dataset}
			\weightStats(\colors, \pattern)
		 -\weightStats(\hat{\colors}, \pattern)
\end{equation*}
%%
where $\hat{\colors}$ is the coloring obtained by running an MCMC chain for $k$ steps from the initial coloring $\colors$. CD forms a local approximation to the likelihood gradient around the neighborhood of $\colors$. Larger $k$ yields more accurate approximations at additional cost; we use $k = 10$. We initialize the weights uniformly to 1 and constrain them to be non-negative, since all terms in the model are log-probabilities.

While the exact weights learned depend on the training dataset, we have noticed several persistent trends.
The perceptual difference, color compatibility, and color name count terms receive the highest weights. These trends coincide well with our intuition that colors should be harmonious, adjacent regions should have sufficient contrast, and colors should be categorically similar to those in the training set.
The lowest weight belongs to the color name similarity term, which suggests that the similarity in how two colors are named is not strongly predictive of their compatibility as an adjacent color pair.
%The information conveyed by this property may be partially redundant with the perceptual difference term. Also, as this property computes the cosine similarity between two 179-dimensional color name count vectors, the dimensionality of the color name space may simply be too high to provide sufficient discrimination for pattern coloring.

\subsection{Implementation}
\label{sec:implementation}

Our prototype implementation of this model is written in the Scala programming language, using the Factorie toolkit for probabilistic modeling~\cite{Factorie}. To evaluate the color compatibility term, it uses the reference MATLAB implementation provided by O'Donovan et al.~\shortcite{ODonovan}.
%A link to the source code can be found on the project website.